\chapter{Extraction de Données Relatives aux Demandes}
%\chapter{Extraction des demandes et résultats correspondants}
\label{chap:quanta}

\section{Introduction}
\label{sec:quanta:introduction}
Au c\oe{}ur de l'analyse des décisions de justice se trouve le concept de demande. Il s'agit d'une réclamation ou requête effectuée par une ou plusieurs parties aux juges. Une partie peut demander des dommages-intérêts en réparation d'un préjudice subi, ou bien un divorce, ou bien des indemnités auxquelles elle pense avoir droit, ou encore une étude d'expert, etc. Les demandes sont fondamentales car l'argumentation au cours de l'affaire a deux buts : faire accepter ses demandes et faire rejeter celle de la partie adverse. L'extraction des demandes et des résultats correspondants, dans un corpus, permet ainsi d'avoir une estimation quantifiée des chances de réussite ou d'échec de certains types de demandes. Les informations qui nous intéressent sont la catégorie de la demande, le quantum (montant) demandé, le sens du résultat (par ex. la demande a-t-elle été acceptée ou rejetée?), et le quantum obtenu (décidé par les juges). Pour pouvoir extraire les demandes et les résultats, il est nécessaire de comprendre comment ils sont exprimés et co-référencés dans les décisions jurisprudentielles. Leur expression peut comporter plus ou moins de complexité avec souvent des références à des jugements antérieurs, des agrégations ou des restrictions (Figure \ref{fig:quanta:expr-dmd-rst}).

\begin{figure}[h]
	\scriptsize
	\centering
	\begin{subfigure}[t]{0.95\textwidth}
		\fbox{\parbox{\textwidth}{Jennifer M., Catherine M. et Sandra M. ... demandent à la Cour de :
				
				- les recevoir régulièrement appelantes incidentes du \textcolor{blue}{jugement du 23/05/2014} ;
				
				- infirmer \textcolor{blue}{le dit jugement} en \textcolor{brown}{toutes ses dispositions} ; ...
				
				Statuant à nouveau ...
				
				- \textcolor{brown}{les condamner au paiement d'une somme de  3 000,00 \euro{} pour procédure abusive et aux entiers dépens} ; }}
		\caption{Exemples d'expression de demandes}\label{fig:quanta:expr-dmd}
	\end{subfigure} 
	
	
	\begin{subfigure}[t]{0.95\textwidth}
		\fbox{\parbox{\textwidth}{La cour, ...  
				
				CONFIRME \textcolor{blue}{le jugement entreprise} en \textcolor{brown}{toutes ses dispositions}.
				
				Y ajoutant
				
				\textcolor{gray}{CONSTATE que Amélanie Gitane P. épouse M. est défaillante à rapporter la preuve
					d'une occupation trentenaire lui permettant d'invoquer la prescription
					acquisitive de la parcelle BH 377 située [...].}
				
				\textcolor{gray}{DEBOUTE Amélanie Gitane P. épouse M. de sa demande en dommages et intérêts.}
				
				\textcolor{gray}{CONDAMNE Amélanie Gitane P. épouse M. aux dépens d'appel.}
				
				\textcolor{gray}{DIT n'y avoir lieu à l'application de l'article 700 du Code de Procédure Civile.}
		}}
		\caption{Exemple d'expression de résultat}\label{fig:quanta:expr-rst}
	\end{subfigure}
	\caption{Expressions \textcolor{gray}{simples}, ou comprenant des  \textcolor{blue}{références} et  des \textcolor{brown}{agrégations} (extraits de la décision 14/01082 de la cour d'appel de Saint-Denis (Réunion))}\label{fig:quanta:expr-dmd-rst}
\end{figure}


\subsection{Données cibles à extraire}

\subsubsection{Catégorie de demande}

Une catégorie $c$ de demande regroupe les prétentions qui sont de même nature par le fait qu'elles partagent deux aspects: l'objet demandé (par ex. dommages-intérêts, amende, déclaration de créance) et le fondement c'est-à-dire les règles ou normes ou principes juridiques qui fondent la demande (par ex. article 700 du code de procédure civile). Des expressions particulières sont souvent utilisées pour faire référence aux catégories (Tableau \ref{tab:quanta:exemple-categorie}).

\begin{table}[h!]
\scriptsize
\begin{tabular}{|c|p{0.35\textwidth}|p{0.15\textwidth}|p{0.3\textwidth}|}
\hline
\textbf{Label} & \textbf{Expression nominative }                                     & \textbf{Objet}                                                       & \textbf{Fondement}                                                                 \\ \hline
acpa & amende civile pour abus de procédure                         & amende civile                                               & Articles 32-1 code de procédure civile + 559 code de procédure civile  \\ \hline
concdel & dommages-intérêts pour concurrence déloyale                  & dommages-intérêts                                           & Article 1382 du code civil                                             \\ \hline
danais & dommages-intérêts pour abus de procédure                   & dommages-intérêts                                           & Articles 32-1 code de procédure civile + 1382 code de procédure civile \\ \hline
dcppc & déclaration de créance au passif de la procédure collective  & déclaration de créance & L622-24 code de commerce                                               \\ \hline
doris & dommages-intérêts pour trouble de voisinage                  & dommages-intérêts                                           & principe de responsabilité pour trouble anormal de voisinage           \\ \hline
styx & frais irrépétibles                                          & dommages-intérêts                                           & Article 700 du code de procédure civile                                 \\ \hline
\end{tabular}
\textit{Les labels ont été définis particulièrement pour cette étude, n'existent pas par conséquent dans le langage juridique.}
\caption{Exemples de catégories de demandes}\label{tab:quanta:exemple-categorie}
\end{table}

\subsubsection{Quantum demandé}

Le quantum demandé quantifie l'objet de la demande. Nous le notons $q_d$. Par exemple, dans l'exemple de la Figure \ref{fig:quanta:expr-dmd}, "3000 \euro{}" est le quantum demandé pour dommages-intérêts pour procédure abusive. Bien que, dans cette étude, nous ne nous intéressons particulièrement qu'aux montants d'argent, le quantum peut être une durée (garde d'enfant, ou emprisonnement, etc.). Toutes les catégories demandes n'ont pas un quantum (par ex. une demande de divorce) et seul le sens du résultat sera la donnée à extraire dans ce cas.

\subsubsection{Sens du résultat}

Le sens du résultat est l'interprétation de la réponse des juges à une demande. Nous le notons $s_r$. En général, le sens peut être positif si la demande a été acceptée ou négatif si la demande a été rejetée. Il arrive aussi que le résultat soit reporté à un jugement futur (un sursis à statuer est alors prononcé). 

\subsubsection{Quantum obtenu ou résultat}

Le quantum obtenu quantifie le résultat ou la réponse des juges. Nous le notons $q_r$. Il est en général inférieur ou égal au quantum demandé. Si la demande est rejetée, 
$q_r$ est évidemment nul même si cela n'est pas explicitement mentionné dans le document. Il doit être de la même nature que le quantum demandé (montant d'argent ou durée).


\subsection{Expression, défis et indicateurs d'extraction}

Les demandes sont décrites à la fin de la section d'exposé des faits, procédures, moyens et prétentions des parties (section LITIGE). Elles rentrent donc dans les "moyens et prétentions des parties" qui regroupent les demandes et les arguments des parties. Quant aux résultats, ils sont décrits dans la section DISPOSITIF et dans la section MOTIFS (raisonnement des juges). Les demandes sont exprimées en paragraphe où chaque paragraphe correspond soit à une partie, soit à un groupe de partie partageant les mêmes demandes (par ex. des époux). Le paragraphe est parfois organisé en liste dont chaque élément exprime une ou plusieurs demandes, ou fait référence à un jugement antérieur. Les résultats ont aussi la forme de liste dans la section DISPOSITIF. Par contre, dans les motifs de la décision, les raisonnements sont organisés en paragraphes, et ordonnés catégorie après catégorie. Le résultat est donné à la fin du groupe de paragraphes associé à la catégorie.


 Cette pseudo-structure n'est pas standard et elle impose de nombreux défis à relever. D'une part, la séparation des demandes et des résultats rend difficile la résolution de référence entre prétentions et résultats. En effet, une décision jurisprudentielle porte sur plusieurs demandes de catégorie différentes dont il faut identifier la catégorie, le quantum demandé, le sens du résultat et le quantum obtenu. Il est important de faire correspondre un quantum demandé extrait au sens et au quantum du résultat qui font référence à la même demande. Le problème de co-référence est généré aussi par la redondance; par ex. les résultats exprimés dans les MOTIFS sont résumés dans le DISPOSITIF. D'autre part, les références aux jugements antérieurs exigent de résoudre des références aux résultats de jugements antérieurs qui sont, heureusement, rappelés dans le même document. Notons aussi que les difficultés liés aux agrégations (par ex. "\textit{infirmer ... en toutes ces dispositions}") et aux restrictions/sélections (par ex. "\textit{infirme le jugement ... sauf en ce qu'il a condamné M. A. ...}") devraient être résolues. Par ailleurs, les catégories de demandes sont nombreuses (500+ code NAC(?)) mais ne sont pas toutes présentes dans toutes les décisions. Toutes ses contraintes démontrent bien la diversité et l'état non-structuré des documents. Elles induisent des difficultés pour l'annotation manuelle de suffisamment données de référence et la modélisation de l'approche d'extraction. Cependant, nous avons remarqué quelques indicateurs qui pourraient être exploités implicitement ou explicitement.

On pourrait au préalable annoter les candidats potentiels de quanta. Nous nous sommes intéressés aux demandes dont les quanta sont des sommes d'argent. Les mentions de somme d'argent sont généralement la forme \og \texttt{[valeur] [monnaie]} \fg{} (par ex. \texttt{3000 \euro}, \texttt{15 503 676 francs}, \texttt{un euro}, \texttt{339.000 XPF}). Des centimes apparaissent parfois (par ex. \texttt{dix huit euros et soixante quatorze centimes}, \texttt{26'977 \euro{}  19}).  Ainsi, en répertoriant les unités monétaires mentionnées dans les décisions, il est possible d'annoter les sommes d'argent à l'aide d'une expression régulière comme par exemple \texttt{[0-9]([0-9] |[,.]|\textbackslash s)*(euros|francs|\euro)}. Même s'il est difficile de reconnaître des sommes d'argent écrites en lettre, il faut remarqué que l'équivalent en chiffre est généralement mentionné tout près (par ex. \texttt{neuf mille cinq cent soixante six euros et quatre vingt sept centimes (9566,87 \euro{}  )}). 
%\begin{equation} %\scriptsize
%\splitdfrac{\backslash [0-9](\backslash [0-9]|[',.]|\backslash s)*}
%{(euro[s]\left\{0,1\right\}|franc[s]\left\{0,1\right\}|\euro{}|F|CFP|XPF|EUR|EUROS)( |\$)}\label{equation:quanta:regex-argent} % Ђ 
%\splitdfrac{\backslash [0-9](\backslash [0-9]|[',.]|\backslash s)*([Ee]uro[s]\left\{0,1\right\}|[Ff]ranc[s]\left\{0,1\right\}|\text{\euro}|\text{\euro}uros|}{F[.]\left\{0,1\right\}|Fr|XPF|CFP|EUR|EUROS|Mark|US|([i]))( |\$)}% Ђ 
%\end{equation}
%\texttt{\small $\backslash$p{Digit}($\backslash$p{Digit}|[',.]|\ $\backslash$s)*(euro[s]{0,1}|franc[s]{0,1}|\euro{}|F|CFP|EUR|EUROS)( |\$)}
%\p{Digit}(\p{Digit}|[',.]|\s)*([Ee]uro[s]{0,1}|[Ff]ranc[s]{0,1}|€|€uros|F[.]{0,1}|Fr|XPF|CFP|EUR|EUROS|Mark|US|([i])|([Ђ]))( |$)

La terminologie utilisée est aussi un bon indicateur pour reconnaître des demandes et des résultats. En effet, le vocabulaire utilisé est très souvent propre aux types de demandes. Par exemple le dernier élément de la Figure \ref{fig:quanta:expr-dmd} comprend le terme "\textit{pour procédure abusive}" qui est près d'une somme d'argent (\textit{3000 \euro{}}); il est donc probable que ce type de terme assez particulier soit un bon indicateur de la position des quanta. Par ailleurs, des verbes particuliers sont utilisés pour exprimer les prétentions et résultats : infirmer, confirmer, constater, débouter, dire, ... %Comme autres formes récurrentes, on pourrait citer l'ordre des demandes (resp. résultats). Généralement, on a les constats, les références aux jugements antérieurs, les demandes principales (?) et secondaires (?).


\section{Formulation du problème}
\label{sec:quanta:formulation}
Pour formuler le problème, nous avons tenu compte principalement de deux faits:
\begin{enumerate}
    \item Une décision comprend plusieurs demandes de catégories similaires ou différentes;
    \item  Il existe un grand nombre de catégories (500+); ce qui rend difficile l'annotation d'un jeu de données de référence pour couvrir toutes ces catégories.
\end{enumerate}

Nous avons par conséquent opter pour une extraction par catégorie. L'idée est de pouvoir  rajouter progressivement de nouvelles catégories. Une exécution du système d'extraction permet ainsi d'extraire uniquement les demandes d'une seule catégorie. L'annotation manuelle d'exemples est focaliser sur une catégorie à chaque fois afin que la tâche soit plus facile pour les experts. Le protocole d'annotation se déroule en étapes: 
\begin{enumerate}
    \item choisir une catégorie $c$ : définition d'un nom, de l'objet et du fondement;
    \item rechercher par mots-clés des documents susceptibles de contenir la catégorie (par exemple sur le site internet de LexisNexis);
    \item parmi les documents trouvés, choisir quelques uns de ceux qui contiennent effectivement des demandes de la catégorie et former ainsi un corpus $D_{c}$; 
    \item lire chaque document choisi pour identifier toutes les demandes présentes de la catégories tout en remplissant le tableau des demandes de références dont un extrait est illustré par le Tableau \ref{tab:quanta:tab-annotations};
    \item collecter quelques documents ne contenant pas de demande de la catégorie et constituer ainsi un corpus $D_{\overline{c}}$.
\end{enumerate}

Le résultat d'une phase d'annotation comprend ainsi un tableau des demandes, deux corpus de décisions $D_{c}$ et $D_{\overline{c}}$.

\begin{table}[!htb]
\includegraphics[width=\textwidth]{tab-annotations.png}
\scriptsize{Les noms des champs sont sur les 2 premières lignes et les demandes sont données en exemple pour la catégorie \textit{dommages-intérêts sur le fondement de l'article 700 du code de procédure civile} (décision 14/06911 de la cour d'appel de Lyon).}
\caption{Extrait du tableau d'annotations manuelles des demandes.} \label{tab:quanta:tab-annotations}
\end{table}

Pour s'adapter à l'annotation manuelle par catégorie, le problème est décomposé grossièrement en deux principales tâches:
\begin{description}
\item[Tâche 1:] Détecter les catégories présentes dans le document pour n'appliquer l'extraction  que de ces catégories;
\item[Tâche 2:] Pour chaque catégorie identifiée, extraire les demandes:
\begin{enumerate}
	\item identification des données: quanta demandés ($q_d$), quanta obtenus ($q_r$), et sens du résultat ($s_r$);
	\item résolution des références ou des liens entre données de même demande pour former les triplets ($q_d, s_r, q_r$).
\end{enumerate}
\end{description}

L'annotation des candidats de quanta, les sommes d'argent dans notre cas, doit être réalisée préalablement à la seconde tâche.

 Dans la section suivante, nous synthétisons l'analogie avec des problématiques couramment traités et explorons les approches proposées dans des travaux publiés.

\section{Travaux connexes}
\label{sec:quanta:biblio}
Chacune de ses tâches se rapproche d'une tâche traitée dans la littérature, et nous donne ainsi des voies de solution. En effet, la détection de catégories dans les décisions peut être modélisée comme un problème de classification de document. La seconde tâche se rapproche plus des problématiques d'extraction d'entités complexes à champs/attributs comme l'extraction d'évènements, le remplissage de champs, ou encore l'extraction de relations et la résolution de référencement.

\subsection{Problèmes analogues: extraction de structures}% avec des problématiques d'extraction d'information}

Les demandes ressemblent aux structures telles que les relations ou les évènements. En effet, les champs définis par \citet{ace2005relation} et \citet{ace2005event} se rapprochent de ceux que visés lors de l'extraction des demandes comme l'illustre le Tableau \ref{tab:quanta:analogie-relation-evt}. Plus précisément, une catégorie de demande correspond à un type d'évènement ou de relation entre deux entités. Les arguments qui participent à l'évènement \og demande \fg{} ou à la relation \og demande-résultat \fg{} sont le quantum demandé et le quantum résultat. Le sens du résultat représente la classe de la structure \og demande \fg{}.

\begin{table}[h]
	\scriptsize
	\begin{tabular}{|p{0.12\textwidth}|p{0.21\textwidth}|p{0.27\textwidth}|p{0.27\textwidth}|}
		\hline		%\textbf{Champs} 
		 & \textbf{Relation \citep{ace2005relation}}  & \textbf{Événement \citep{ace2005event}} & \textbf{Analogie chez les demandes} \\ \hline
		\textbf{Type} & Org-Aff.Student-Alum & Die & Catégorie="Dommages-intérêts pour procédure abusive" \\ \hline
		\textbf{Passage} (\textit{extend}) & \textit{Card graduated from the University of South Carolina}  & "Il est mort hier d'une insuffisance rénale."  & (\textit{Figure \ref{fig:quanta:expr-dmd-rst}}) \\ \hline
		\textbf{Déclencheur (\textit{trigger})} & - & "mort" & "procédure abusive"\\ \hline
		\textbf{Participants ou Arguments  (\textit{arguments})} & Arg1="Card" \linebreak Arg2="the University of South
		Carolina"& Victim-Arg="il" \linebreak Time-Arg="hier"  & Quantum-demandé="3000\euro{}"\linebreak  Quantum-obtenu="0 \euro{}"\ \\ \hline
		\textbf{Classes  (\textit{attributes, classes})} & Asserted & Polarity=POSITIVE, Tense=PAST & Sens-résultat="Rejeté" \\ \hline
	\end{tabular}
	\caption{Exemples d'analogie entre relations, évènements et demandes} \label{tab:quanta:analogie-relation-evt}
\end{table}

\subsection{Approches d'extraction d'éléments structurés}
L'extraction d'éléments structurés a généralement une formulation modulaire du problème en tâches plus simples. D'une part, on a l'identification des déclencheurs et des arguments. D'autre part, une mise en correspondance relie les arguments et déclencheurs qui participent à la même relation ou au même évènement. Les classes peuvent être déterminées par classification du passage associé. Cette décomposition a permis à de nombreuses méthodes de voir le jour. 

L'approche traditionnelle consiste à traiter le problème séquentiellement. Chaque étape correspond à un module et la sortie d'une étape est l'entrée de la suivante. C'est ainsi que \citet{ahn2006stages} définit un enchaînement de classificateurs (k-plus-proches-voisins \citep{cover1967knn} vs. classificateur d'entropie maximum \citep{nigam1999maxent}), pour extraire des champs des évènements tels que définis par \citet{ace2005event}. même si les différents modules sont plus facile à résoudre, ce type d'architecture souffre de l'accumulation et la propagation des erreurs d'une étape à la suivante, ainsi que de la non exploitation de l'interdépendance entre les tâches. Par conséquent, l'inférence jointe des champs est préconisée. Celle-ci peut-être faite par une modélisation probabiliste conditionnelle ou neuronale.

Toujours sur le corpus d'ACE, \citet{yang2016jointEntityEvt} estiment la probabilité conditionnelle jointe du type d'entité $t_i$, les rôles des arguments $r_{i\cdot}$ et les types d'entités qui remplissent ces rôles $a.$: $p_\theta(t_i,r_{i\cdot},a. \vert i, N_i, x)$ avec $i$ un déclencheur candidat, $N_i$ l'ensemble des entités candidates qui sont des potentiels arguments pour $i$, et $x$ est le document. Par ailleurs, \citet{nguyen2016jointtrgarg} illustrent l'utilisation des réseaux de neurones profonds avec une couche pour la prédiction du déclencheur, une autre pour le rôle des arguments, et la dernière encode la dépendance entre les labels de déclencheurs et les rôles d'arguments. 

L'annotation d'\citet{ace2005event} est un marquage des champs dans le texte, et par conséquent, la position ou l'occurrence des champs est indiquée (\og annotation au niveau du segment de mot \fg{}). Seulement, il est difficile dans le cadre réel d'annoter les données sous cette forme. Comme dans notre cas, les données sont généralement annotées dans un tableau, hors des textes d'où ils proviennent. Il est donc nécessaire de retrouver leur position sans supervision. \citet{palm2017e2e-dnn} propose dans cette logique une architecture de réseaux de neurones point-à-point qu'ils ont expérimentés sur des corpus de requêtes de recherche de restaurant et films \citep{liu2013mitmovierestaurant} ou de réservation de billets d'avion \citep{price1990atis}. Ils se sont intéressés au problème de remplissage de champs en apprenant la correspondance entre les textes et les valeurs de sorties. Leur modèle est basé sur les réseaux de pointeurs \citep{vinyals2015pointernetworks} qui sont des modèles séquence-à-séquence avec attention, dans lesquelles la sortie est une position de la séquence d'entrée. Le modèle proposé consiste en un encodeur de la phrase et des contextes, plusieurs décodeurs (un pour chaque champ). 

L'avantage de l'utilisation des réseaux de neurones est la capacité d'apprendre des caractéristiques automatiques contrairement aux modèles probabilistes qui exigent une ingénierie manuelle des caractéristiques. Par contre, il est beaucoup plus facile d'utiliser les modèles probabilistes sur des corpus de faible taille et des longs textes comme c'est le cas pour notre problème.


\subsection{Extraction de la terminologie d'un domaine}
L'identification des arguments peut bénéficier de la position relative avec des termes-clés ou \og déclencheurs \fg{}. Ils sont caractéristiques des types d'évènements car ils semblent être des indicateurs incontournables non seulement de l'énoncé mais aussi de la position des arguments. Qu'ils soient identifiés préalablement aux arguments ou conjointement avec ces derniers, les déclencheurs sont généralement appris de manière supervisée c'est-à-dire à partir d'exemples  de déclencheurs manuellement annotés dans des énoncés d'évènements. L'annotation manuelle de tels termes étant fastidieuse, il serait préférable d'en déterminer lorsqu'on ne dispose pas d'exemples. C'est notamment notre situation, où nous ne disposons pas d'une liste de termes caractéristiques des catégories de demandes. Fort heureusement, la recherche d'information, l'apprentissage d'ontologie et d'autres tâches d'analyse de texte comme la classification de documents ont encouragé le développement d'approches d'extraction de termes-clés. Nous discutons ici de quelques méthodes statistiques qui peuvent permettre d'identifier la terminologie d'expression des demandes d'une catégorie donnée. Il s'agit de fonctions de sélection de caractéristiques d'un corpus qui pondère un descripteur \footnote{Un descripteur peut être soit un mot, un n-gramme, la racine d'un mot, ou tout autre caractéristique syntaxique ou sémantique}. On les appelle aussi pondérateurs globales parce qu'elles sont calculées à l'échelle d'un corpus, contrairement au pondérateur locaux qui mesurent l'importance d'un terme dans un texte.

 Lorsque la fonction n'utilise que le corpus représentatif du domaine d'intérêt, elle mesure ainsi le degré d'importance du terme dans le langage d'un domaine particulier ou une classe particulière de documents. Par exemple, la fonction \og fréquence de document \fg{} (\textit{DF - Document Frequency}) mesure l'importance d'un terme en lui affectant la proportion de documents qui le contiennent dans un corpus global considéré. De telles fonctions sont qualifiées de non-supervisées contrairement à celles qui se calculent entre différents corpus  et par conséquent utilisent les labels des données d'entraînement \citep{lan2009termweighting, wu2017balancingtermweight}. Ces dernières mesure l'importance du terme dans la discrimination (ou la différence) entre le domaine d'intérêt et les autres corpus. Un exemple simple s'obtient en faisant la différence de \og fréquence de document \fg{} d'un terme entre un corpus $c$ et sont complémentaire $\overline{c}$. Nous avons explorer l'utilisation de quelques méthodes pour la classification et qui sont formulées ici en utilisant les notations suivantes:

%\subsubsection{Méthodes statistiques}
% LISTES POUR CHAQUE CATÉGORIE

$t$ : un terme \\
$d$: un document \\
$\vert t \vert$ : longueur de $t$ (nombre de mots) \\
$c$ : la catégorie (domaine ciblé) \\
$\overline{c}$ : la classe complémentaire ou négative \\
$D$: ensemble global des documents \\
$D_{c}$: ensemble des documents de $c$\\
$\vert D_{c} \vert$: nombre de documents de $c$\\
$N_{t}$: nombre de documents contenant $t$\\
$N_{\overline{t}}$: nombre de documents ne contenant pas $t$\\
$N_{t,c}$ : nombre de documents de $c$ contenant $t$ \\
$N_{\overline{t},c}$ : nombre de documents de $c$ ne contenant pas $t$ \\
$\vert D \vert$ : nombre total de documents ($\vert D \vert = \vert D_{c} \vert + \vert D_{\overline{c}} \vert$)\\
$DF_c$ : proportion de documents du corpus appartenant à $c$ (probabilité qu'un texte pris au hasard soit de la classe $c$ )\\
$DF_t$: proportion de documents du corpus contenant $t$ (\textit{Document Frequency})\\
$DF_{t \vert c}$ : proportion de documents contenant $t$ dans le corpus de $c$ ($DF_{t \vert c} = \frac{N_{t,c}}{N_{c}}$) \\
$DF_{c \vert t}$ : proportion de documents appartenant à $c$ dans l'ensemble de ceux qui contiennent $t$  \\
$TF_{t, d}$: nombre d'occurrence de $t$ dans $d$ (\textit{Term Frequency}) \\

\paragraph{Mesures non-supervisées}
NValue, CValue, IDF et co.
 La fréquence inverse de document $idf$ \cite{sparck1972idf} et ses variantes $pidf$ et $bidf$ accordent plus d'importance aux termes rares.  

\paragraph{Mesures supervisées}
RF, MARASCUILO, TEST DE PROPORTIONS, CHI2, ...



\subsubsection{Discussions}
\textcolor{red}{PRISE EN COMPTE DE LA LONGUEUR VARIÉE ($\log(l) * f(t)$ ou $l^a * w^b$ / DE L'IMBRICATION / DU CONTEXTE DES TERMES;;;; AFFINER LA LISTE: ENCHAINEMENT FILTRES > MÉTRIQUES STATS > FONCTION CONTRASTIVE}
\cite{LossioVentura2014biotex}, \cite{Bonin2010multiwordncvalue}


\section{Détection des catégories par classification}

Étant données l'ensemble $D_{\overline{c_i}}$ des documents ne comprenant aucune demande de la catégorie d'intérêt $c_i$, nous proposons de modéliser la tâche de détection des catégories en une tâche de classification. Pour chaque catégorie, un classifieur binaire de document est entraîné pour déterminer si le document analysé contient ou pas une demande de la catégorie. Pour cela, chaque document $d_j$ est représenté sous une forme vectorielle traditionnelle du type TF-IDF (\textit{term frequency - inverse document frequency}) où chaque dimension représente un mot dont le poids est le produit normalisé d'un poids $gw$ global au corpus du mot et d'un poids $lw$ local au document: $w(t_k, d_j) = lw(t_k, d_j) \times gw(t_k) \times nf(d_j)$, où $nf$ est le facteur de normalisation. 


\section{Extraction des demandes}
\label{sec:quanta:attributs}

L'étude consiste en la proposition et la comparaison empirique d'adaptations des approches d'extraction de structure à savoir: l'usage de règles, le chainage d'extracteur élémentaire, et l'inférence jointe.


\subsection{Méthode 1: extraction par règles et termes-clés}
\label{subsec:quanta:attributs:regles}

%\textcolor{red}{Cité la localisation des unités de mésure / considérer le découpage en phrases à la place du découpage avec les verbes introductifs. Formaliser l'algorithme (si possible donner la complexité et le temps d'extraction moyen par document)}
Pour chacune des catégories détectées, nous proposons ici une chaîne d'extraction à base de termes-clés. Il s'agit d'une approche qui tente de reproduire une lecture naïve du document. Elle est ainsi basée sur des sortes de formes d'expression répétitives et inspirées de nos lectures des documents. La technique consiste à marquer les énoncés de demandes et résultats. Dans ces passages, les quanta sont localisés à proximité de termes-clés caractérisant la catégorie. Par exemple, la Figure \ref{fig:quanta:exemple-proximite} présente un extrait de passage exprimant une demande d'\textit{amende civile pour procédure abusive}.

\subsubsection{Annotation des énoncés et termes-clés}

 La Figure \ref{fig:quanta:exemple-proximite-original} présente l'extrait original et la Figure \ref{fig:quanta:exemple-proximite-marquage} présente le résultat de notre marquage automatique que nous proposons. Les passages, les sommes d'argent, et les termes-clefs sont marqués avec les balises XML resp. \verb=<demande>=, \verb=<argent>=, \verb=<terme-clef>=. Dans cet exemple, on remarque bien que le quantum demandé (\textit{1.500 euros}) se trouve très près de terme-clefs associables à la catégorie \textit{acpa} ("\textit{amende civile}" et "\textit{pour procédure abusive}"). 

\begin{figure}[!htb]
	\scriptsize
	\centering
	\begin{subfigure}[t]{0.95\textwidth}
		\fbox{\parbox{\textwidth}{
				" ... 
				
				- débouter M. S. de ... % l' ensemble de ses demandes
				
				\textbf{- le condamner à payer une amende civile de 1.500 euros pour procédure abusive} ...
				
				- le condamner à payer la somme ..."
		}}
		\caption{Extrait original d'énoncé de demande avant marquage}\label{fig:quanta:exemple-proximite-original}
	\end{subfigure} 
	
	
	\begin{subfigure}[t]{0.95\textwidth}
		\fbox{\parbox{\textwidth}{
				" ... 
				
				- débouter M. S. de ... % l' ensemble de ses demandes
				
				- le \textbf{<demande categorie="acpa">}\underline{condamner} à payer une <terme-clef categorie="acpa">\textbf{amende civile}</terme-clef> de <argent> \textbf{1.500 euros} </argent> <terme-clef categorie="acpa"> \textbf{pour procédure abusive}</terme-clef> ...
				
				- le\textbf{</demande>} \underline{condamner} à payer la somme ..."
		}}
		\caption{Énoncé, sommes d'argent, et termes-clés marqués}\label{fig:quanta:exemple-proximite-marquage}
	\end{subfigure}
	%\caption{Exemple de passage de demande: le quantum demandé est une somme d'argent à proximité des terme-clés}
	\caption{Illustration de la proximité des quantas et termes-clés}
	\label{fig:quanta:exemple-proximite}
\end{figure}

Les énoncés de demande se distinguent de ceux des résultats par leur position dans le document (les demandes dans la section LITIGE et les résultats dans les sections MOTIFS et DISPOSITIF) et par les verbes qui les introduisent (très souvent à l'infinitif pour les demandes et au présent pour les résultats). Nous avons ainsi prédéfini, indépendamment de la catégorie traitée, une liste de mots qui sont généralement des verbes (Tableau \ref{tab:quanta:mots-introductifs}) pour délimiter les demandes et résultats dans leur section respectives. La recherche de passages à l'aide listes de termes n'est pas unique à notre étude. \cite{wyner2010extractlegalelts} utilise par exemple des termes de jugement dans des règles JAPE pour annoter les énoncés de résultats (toute phrase contenant un terme de jugement) : \textit{affirm, grant, deny, reverse, overturn, remand, ...}
\begin{table}
\centering
\scriptsize
 \begin{tabular}{|p{0.28\textwidth}|p{0.3\textwidth}|p{0.12\textwidth}|p{0.11\textwidth}|}
 \hline
 \textbf{Demande} & \multicolumn{3}{c|}{\textbf{Résultat} (organisé par polarité)} \\ \hline
  & \textbf{accepte}  &\textbf{sursis à statuer} & \textbf{rejette}  \\ \hline
 \textit{accorder, admettre, admission, allouer, condamnation, condamner, fixer, laisser, prononcer, ramener, surseoir} & \textit{accorde, accordons, admet, admettons, alloue, allouons, condamne, condamnons, déclare, déclarons, fixe, fixons, laisse, laissons, prononce, prononçons} & \textit{réserve, réservons, sursoit, sursoyons} & \textit{déboute, déboutons, rejette, rejetons} \\ \hline
 \end{tabular}
  \caption{Mots introduisant les énoncés de demandes et de résultats}\label{tab:quanta:mots-introductifs}
 \end{table}

Les termes prédéfinis délimitent les passages de demande et résultat indépendamment de toute catégorie, mais nous ne souhaitons analyser que les passages de la catégorie traitée. Il est donc nécessaire d'identifier les termes-clés indiquant l'expression de cette catégorie. 

\subsubsection{Apprentissage des termes-clés d'une catégorie}

 Nous proposons un apprentissage semi-supervisé de ces termes. L'apprentissage est "supervisé" parce qu'on dispose de 2 corpus annotées pour chaque catégorie $c$: les documents à demande de la catégorie ($D_c$) et des documents sans demande de la catégorie ($D_{\overline{c}}$). L'apprentissage est "semi" parce qu'on ne dispose pas d'exemples de termes caractéristiques de la catégorie, mais uniquement de candidat qui sont en fait les termes de $D_c$. Nous avons utilisé des métriques/tests statistiques d'analyse de proportion pour sélectionner les termes qui sont plus importants dans le corpus $D_c$ que dans $D_{\overline{c}}$. Ces métriques sont listées dans le Tableau \ref{tab:quanta:globalweights}.
 
 \begin{enumerate}
 	\item  pondération et tri décroissant des termes du corpus $D_c \cup D_{\overline{c}}$
 	\item  Sélection des N meilleurs termes (par ex. N=100)
 	\item Filtre des termes donnant le meilleur score sur les données de développement
 \end{enumerate}




%\subsection{Méthode 2: classification des sommes d'argent}
%
%\begin{figure}[!htb]
% \includegraphics[scale=0.6]{extractDmd-archClassifArgent.png}
% \caption{Extraction des demandes par classification des sommes d'argent}\label{fig:quanta:classif}
%\end{figure}
%
%Les deux champs directement accessibles à partir du texte, sont les quanta demandé ($q_d$) et accordé ($q_r$). Pour les demandes à quanta, il est possible de restreindre l'extraction à ces deux variables. Le sens du résultat ($s_r$) est déduit de la valeur extraite du quantum accordé : \[s_r = \left\lbrace \begin{array}{ll}
%"accepte" & \text{si } q_r > 0 \\
%"rejette" & \text{sinon.} \end{array} \right.\]
%
%L'idée est d'extraire les quanta demandés et obtenus puis de d'identifier les paires $(q_d, q_r)$ qui représentent des demandes. Le système recherche les mentions de sommes d'argent qui sont des quanta. La  détection des quanta est réalisable soit par classification individuelle des sommes d'argent, soit par inférence probabiliste du groupe de quanta. 
%
%
%La performance d'une telle approche repose sur deux aspects principaux: la définition des  caractéristiques des objets à classifier, et la résolution des doublons. 
%
%\subsubsection{Définition des caractéristiques}
%
%La considération d'une somme d'argent comme quantum dépend de son contexte de mention et de l'histoire globale du document. Nous combinons plusieurs types de caractéristiques:
%\begin{itemize}
%	\item le plongement sémantique de la somme d'argent;
%	\item l'agrégation pondérée du vecteur des mots qui sont dans la phrase de la somme d'argent;
%    \item le plongement sémantique de la section
%    \item le plongement sémantique du dispositif
%    \item le plongement sémantique du document
%\end{itemize}
%
%Les caractéristiques des paires consiste en l'agrégation des vecteurs des deux sommes par concaténation, max, ou soustraction.
%
%\subsubsection{Résolution des doublons}
%Il s'agit ici des mentions de sommes d'argent à valeurs égales. Certaines sont correspondent au même quantum (par ex. quanta du MOTIFS répétés dans le DISPOSITIF). D'autres représentent des quanta différents.
%
% Le problème des doublons se pose déjà sur les données d'entraînement. En effet, nous devons retrouver à quelle mention de somme d'argent correspond chaque quantum du tableau des annotations manuelles. Si on annote tous les doublons comme quanta, se retrouve avec des demandes en plus. Même si on considère qu'il s'agit de la même demande, on n'en est pas sûr. On peut choisir le plus probable parmi les doublons présents.
%
%%Résolution des doublons: classification de paires apprise sur un dataset généré à partir du comportement observé des détecteur de quanta sur le corpus d'entrainement. (a1, a2) -> (similaire, différent). UNIQUEMENT POUR DES SOMME DE VALEURS EGALES
%
%\textcolor{red}{STATISTIQUES SUR LE TAUX DE DOUBLONS DANS LES DONNÉES ANNOTÉES}
%
%
%\subsection{Méthode 3: prédiction jointe de structure}
%?Apprentissage sur les documents à une seule demande pour limiter les bruits?
%
%Pré-traitement: normalisation des sommes d'argent dans les document (par ex. 3000 euros <argent valeur="3000 euros">ARGENT\_i</argent> $i$ étant la position d'apparition de la mention)
%
%\begin{equation}
%P(D|T,A) = \sum\limits_{i=1}^{\vert D \vert} p_{\theta_1}(d_i = (a_j, a_l) | T, a_j, a_l, A) \cdot p_{\theta_2}(q_{d_i} = a_j | T, a_j, A) \cdot p_{\theta_3}(q_{r_i} = a_l | T, a_l, A)    
%\end{equation}

\subsection{Interprétation des résultats expérimentaux}
Nous analysons ici la capacité des approches proposées à reconnaître efficacement la présence des catégories prédéfinies dans les documents, et à extraire les valeurs des attributs des différentes demandes qui y sont décrites. 


\subsubsection{Annotation des données d'évaluation}
\begin{figure}[h!]
	\includegraphics[width=\textwidth]{chartDataset.png}
	\caption{Répartitions des demandes dans les documents annotées pour chaque catégorie.}\label{fig:quanta:hist-repartition-docs}
\end{figure}
Pour une catégorie $c_i$ de l'ensemble $C$ des catégories existantes, les données de références sont annotées dans un tableau. Chaque ligne décrit une demande. L'annotateur devrait associer deux corpus au tableau. Le premier corpus $D_{c_i}$ comprends les documents d'où proviennent les demandes annotées pour $c_i$. Le second corpus $D_{\overline{c_i}}$ contient des exemples de documents ne contenant aucune demande de catégorie $c_i$. Le corpus $D_{\overline{c_i}}$ permet de s'assurer que le système n'extrait pas de demande dans des documents ne discutant pas de $c_i$.  Pour notre étude, un expert a extrait manuellement des demandes des 6 catégories du Tableau \ref{tab:quanta:exemple-categorie}. Nous considérons que les demandes de type $c_i$, présentes dans le corpus $D_{c_i} \cup D_{\overline{c_i}}$, ont été toutes annotées dans le tableau. La répartition, des documents traités durant ce processus, est donnée par l'histogramme de la Figure \ref{fig:quanta:hist-repartition-docs}.  On remarque que, pour toutes les catégories, les documents à une seule demande sont en général majoritaires (barres bleues). Quelques documents ne comprenant aucune demande de la catégorie d'intérêt ont été aussi rassemblés (barres grises). Il faut aussi noter que malgré la non annotation des demandes directement dans les documents mais plutôt dans un tableau (annotation externe), l'annotation reste une tâche très difficile. Le très faible nombre de documents traités en est la conséquence. Le nombre  maximum pour une catégorie n'a été que de 198 documents (barres vertes) \textcolor{red}{[DURÉE D'ANNOTATION? QUELLE EST LA VITESSE MOYENNE D'EXTRACTION MANUELLE DES DEMANDES DANS UN DOCUMENT?]}.


Avant l'évaluation, nous avons vérifié que les valeurs annotées existaient bel et bien dans les documents. Le calcul du taux de quanta mentionnés donne une idée de la borne supérieure de performance qu'une méthode d'extraction peut atteindre. D'autre part il faut admettre qu'il ne s'agit que d'une comparaison entre sommes d'argent juste pour savoir si une somme, de la même valeur que le quantum, est présente dans le document. Rien n'assure que la somme mentionnée est le quantum recherché.

\begin{table}[!htb]
	\scriptsize
	\begin{tabular}{|l|l|l|l|l|l|l|}
		\hline
		%\textbf{Catégorie}
		 & \textbf{\#$q_d$} & \textbf{\#$(q_d\neq 0)$} & \textbf{\# dans doc.} & \textbf{\# dans Litige} & \textbf{\# dans Motifs} & \textbf{\# dans Dispositif} \\ \hline
		acpa               & 23                   & 16                                           & 16 (100\%)                   & 16 (100\%)              & 9 (56.25\%)             & 5 (31.25\%)                 \\ \hline
		concdel            & 58                   & 56                                           & 55 (98.21\%)                 & 55 (98.21\%)            & 7 (12.5\%)              & 2 (3.57\%)                  \\ \hline
		danais             & 208                  & 182                                          & 182 (100\%)                  & 179(100\%)              & 39 (21.43\%)            & 23 (12.64\%)                \\ \hline
		dcppc              & 126                  & 126                                          & 122 (96.83\%)                & 109 (86.51\%)           & 71 (56.35\%)            & 65 (51.59\%)                \\ \hline
		doris              & 94                   & 83                                           & 83 (100\%)                   & 82 (98.80\%)            & 21 (25.30)\%            & 6 (7.23\%)                  \\ \hline
		styx               & 89                   & 86                                           & 86 (100\%)                   & 86 (100\%)              & 12 (13.95\%)            & 9 (10.47\%)                 \\ \hline
	\end{tabular}
\textit{Les pourcentages ne sont calculés que pour les valeurs non nulles}
\caption{Taux de quanta demandés ($q_d$) mentionnés dans les documents annotés} \label{tab:quanta:mentionQd}
\end{table}

\begin{table}[!htb]
	\scriptsize
	\begin{tabular}{|l|l|l|l|l|l|l|}
		\hline
		%\textbf{Catégorie}
		& \textbf{\# $q_r$} & \textbf{\# $q_r\neq 0$} & \textbf{\# dans doc.} & \textbf{\# dans Litige} & \textbf{\# dans Motifs} & \textbf{\# dans Dispositif} \\ \hline
		acpa               & 23                & 6                       & 6 (100\%)             & 3 (50\%)                & 6 (100\%)               & 5 (83.33\%)                 \\ \hline
		concdel            & 58                & 8                       & 8 (100\%)             & 2 (25\%)                & 8 (100\%)               & 6 (75\%)                    \\ \hline
		danais             & 208               & 23                      & 23 (100\%)            & 15 (65.22\%)            & 22 (95.65\%)            & 20 (86.96\%)                \\ \hline
		dcppc              & 126               & 76                      & 75 (98.68\%)          & 55 (72.37\%)            & 56 (73.68\%)            & 64 (84.21\%)                \\ \hline
		doris              & 94                & 44                      & 44 (100\%)            & 28 (63.64\%)            & 40 (90.91)\%            & 24 (54.55\%)                \\ \hline
		styx               & 89                & 30                      & 29 (96.67\%)          & 16 (53.33\%)            & 22 (73.33\%)            & 29 (96.67\%)                \\ \hline
	\end{tabular}
\textit{Les pourcentages ne sont calculés que pour les valeurs non nulles}
\caption{Taux de quanta accordés ($q_r$) mentionnés dans les documents annotés} \label{tab:quanta:mentionQr}
\end{table}

Les tableaux \ref{tab:quanta:mentionQd} et \ref{tab:quanta:mentionQr} donne un aperçu de la présence des valeurs de quanta dans les documents annotés, ainsi que leurs occurrences dans les différentes sections Litige, Motifs, et Dispositif. Les pourcentages ne sont calculés que pour les valeurs non nulles car les valeurs nulles ne sont généralement pas mentionnées. Un quantum demandé est noté nul si l'annotateur n'a pas trouvé sa valeur dans le document. Un quantum accordé est noté nul lorsque la demande est rejeté ou si la valeur n'est pas identifiable dans le document.

 Il est évident qu'en général, lorsqu'un quanta est non nul, sa valeur est identifiable dans le document. Sauf exception faite de quelques quanta qui sont calculés sur la base de valeurs mentionnées. Les taux d'occurrence des valeurs de quanta dans les diverses sections, renforce notre hypothèse selon laquelle il est possible de n'extraire les quanta demandés uniquement dans la section Litige, et les quanta accordés dans les sections Motifs et Dispositif. Le sectionnement préalable des documents trouve ainsi son importance. Malheureusement, la restriction de l'extraction dans une section particulière tend souvent à réduire les possibilités de retrouver le quantum qui se trouve dans une autre section. 

\subsubsection{Métriques d'évaluation}
\paragraph{Reconnaissance de catégorie}

\paragraph{Demandes et attributs}
 Nous évaluons les approches proposées sur l'extraction de 3 données: le quantum demandé $q_d$, le sens du résultat $s_r$ et le quantum obtenu $q_r$. Une demande est donc un triplet $(q_d, s_r, q_r)$. Il est possible d'évaluer le système pour un sous-ensemble $x$ de ce triplet sur les demandes extraites d'un corpus annotées $D$. Nous utilisons les métriques traditionnellement employées en extraction d'information: la précision (Eq. \ref{eq:quanta:precisiondmd}), le rappel (Eq. \ref{eq:quanta:recalldmd}), et la F1-mesure (Eq. \ref{eq:quanta:f1dmd}). 
 \begin{equation}
 Precision_{c_i,x,D} = \frac{TP_{c_i,x,D}}{TP_{c_i,x,D} + FP_{c_i,x,D}}  \label{eq:quanta:precisiondmd}
\end{equation}

\begin{equation}
Rappel_{c_i,x,D} = \frac{TP_{c_i,x,D}}{TP_{c_i,x,D} + FN_{c_i,x,D}} \label{eq:quanta:recalldmd}
\end{equation}

\begin{equation}
F1_{c_i,x,D} =2 \times \frac{Precision_{c_i,x,D} \times Rappel_{c_i,x,D}}{Precision_{c_i,x,D} + Rappel_{c_i,x,D}} \label{eq:quanta:f1dmd}
\end{equation}

Ces mesures sont définies à partir des nombres de vrais positifs ($TP$), faux positifs ($FP$) et faux négatifs ($FN$). Au niveau d'un document $d$:
\begin{itemize}
\item le nombre de vrais positifs $TP_{c_i, x, d}$ est le nombre de demandes extraites de $d$ par le système, qui sont effectivement de la catégorie $c_i$ ;
\item le nombre de faux positifs $FP_{c_i, x, d}$ est le nombre de demandes extraites de $d$ par le système, mais qui ne sont pas des demandes de $c_i$ (demandes en trop);
\item le nombre de faux négatifs $FP_{c_i, x, d}$ est le nombre de demandes annotées comme étant de $c_i$ mais qui n'ont pas pu être extraites par le système (demandes manquées).
\end{itemize}

Au niveau d'un corpus d'évaluation $D$, ces métriques de base sont simplement les sommes de leur correspondant au niveau des documents (Équations \ref{eq:quanta:tpdmd}, \ref{eq:quanta:fpdmd}, et \ref{eq:quanta:fndmd}).

\begin{equation}
TP_{c_i,x,D} = \sum\limits_{d_j \in D} TP_{c_i,x,d_j} \label{eq:quanta:tpdmd}
\end{equation}

\begin{equation}
FP_{c_i,x,D} = \sum\limits_{d_j \in D} FP_{c_i,x,d_j} \label{eq:quanta:fpdmd}
\end{equation}

\begin{equation}
FN_{c_i,x,D} = \sum\limits_{d_j \in D} FN_{c_i,x,d_j} \label{eq:quanta:fndmd}
\end{equation}


La définition de la qualité d'une donnée extraite reste la question fondamentale de l'évaluation. Durant l'annotation, les données sont reportées dans le tableau sous une forme qui peut être différente de la mention dans le document. Par exemple,  La valeur observée et la valeur reportée restent néanmoins égales. Il est donc nécessaire de ne comparer que les valeurs. Pour le sens du résultat, la valeur est catégorique, et par conséquent, facilement comparable. En effet, il suffit de comparer les labels. Par contre, les quanta sont des sommes d'argent i.e. des quantités à valeur et unité monétaire. Pour simplifier, nous avons considéré que l'unité est la même pour les données extraites et annotées pour un même document. Pour obtenir la valeur, nous ramenons la mention extraite à un nombre décimal. Le symbole de la décimale étant la virgule (\og , \fg) en Français, il suffit d'éliminer, de la somme d'argent, tous les caractères différents des chiffres et de la virgule; puis remplacer cette dernière par un point. Par exemple, la valeur de \og 3 000 \euro \fg est $3000$, celle de \og 265 ' 550 , 83 euros \fg est $265550.83$ ).



\subsubsection{Détection des catégories par classification}

Nous avons évalué la classification binaire avec quatre classifieurs traditionnels: le classifieur naïf bayésien, l'arbre de décision, les K plus proches voisins (KNN), et la machine à vecteurs de support. A chaque entraînement, s'exécute une sélection de modèle par validation croisée sur les données d'entraînement; elle a pour but de sélectionner la métrique locale et la métrique globale appropriée. Les résultats obtenu par 5-folds cross validation sont présentés sur le tableau \ref{tab:quanta:resultat-detect-cat}.  D'après les résultats, La tâche 1 est relativement aisée car les classifieurs traditionnels détectent parfaitement la présence ou non d'une catégorie dans les documents. \textcolor{red}{[DEFINITION DES MÉTRIQUES D'ÉVALUATION DE LA CLASSIFICATION]}

\begin{table}[!h]
	\scriptsize
	\centering
	\begin{tabular}{l|c@{\hskip 0.1in}lllc@{\hskip 0.1in}lllc@{\hskip 0.1in}lllc@{\hskip 0.1in}lll}
		\hline\noalign{\smallskip}
		&   \multicolumn{3}{c}{Naïf Bayésien}    &    \multicolumn{3}{c}{Arbre de décision}   &  \multicolumn{3}{c}{KNN}  & \multicolumn{3}{c}{SVM}     \\       
		\noalign{\smallskip}
		\hline
		\noalign{\smallskip}
		%Categorie  
		& P     & R     & F1    & P     & R     & F1    & P     & R     & F1    & P     & R     & F1    \\        
		\noalign{\smallskip}
		\hline
		\noalign{\smallskip}
		acpa    & 1.0 & 1.0 & 1.0 & 0.996 & 0.955 & 0.972 & 1.0 & 1.0 & 1.0 & 0.996 & 0.955 & 0.972 \\
		concdel & 1.0 & 1.0 & 1.0 & 1.0 & 1.0 & 1.0 & 1.0 & 1.0 & 1.0 & 0.995 & 0.967 & 0.979 \\
		danais  & 0.988 & 0.989 & 0.988 & 0.996 & 0.995 & 0.995 & 0.995 & 0.995 & 0.995 & 0.993 & 0.993 & 0.993 \\
		dcppc   & 1.0 & 1.0 & 1.0 & 1.0 & 1.0 & 1.0 & 1.0 & 1.0 & 1.0 & 1.0 & 1.0 & 1.0 \\
		doris   & 1.0 & 1.0 & 1.0 & 1.0 & 1.0 & 1.0 & 1.0 & 1.0 & 1.0 & 1.0 & 1.0 & 1.0 \\
		styx    & 1.0 & 1.0 & 1.0 & 0.984 & 0.983 & 0.983 & 1.0 & 1.0 & 1.0 & 1.0 & 1.0 & 1.0 \\
		\hline
	\end{tabular}
	\caption{Résultats d'une 5-fold validation croisée pour la détection catégorie  (P= Précision, R=Rappel, F1 = F1-mesure)}\label{tab:quanta:resultat-detect-cat}
\end{table}

\subsubsection{Comparaison des métriques de pondération des termes}
\begin{table}[]
	\begin{tabular}{|l|l|l|l|l|l|l|}
		\hline
		& \textit{acpa}  & \textit{concdel} & \textit{danais} & \textit{dcppc} & \textit{doris} & \textit{styx}  \\ \hline
		\textit{BIDF}       & 32.16          & 26.08            & 28.76           & 22.08          & 10.19          & \textbf{55.59} \\ \hline
		\textit{CHI2}       & 61.49          & 27.76            & 44.33           & 27.97          & 5.83           & \textbf{55.59} \\ \hline
		\textit{DBIDF}      & 46.99          & 25.67            & \textbf{53.72}  & 29.77          & 6.46           & 55.27          \\ \hline
		\textit{DELTADF}    & 61.49          & 25.97            & 49.46           & 27.97          & 9.61           & 55.1           \\ \hline
		\textit{DSIDF}      & 46.99          & 27.4             & 53.43           & 27.85          & 4.46           & 55.1           \\ \hline
		\textit{GSS}        & 61.49          & 25.97            & 49.46           & 27.97          & 9.61           & 55.1           \\ \hline
		\textit{IDF}        & 32.16          & 26.55            & 25.21           & 22.08          & 10.21          & 55.1           \\ \hline
		\textit{IG}         & 25.68          & 28.6             & 28.4            & 18.47          & \textbf{18.68} & 54.34          \\ \hline
		\textit{KLD}        & 5              & 5                & 29.45           & 16.66          & 1.43           & 31.99          \\ \hline
		\textit{MARASCUILO} & \textbf{68.49} & 25.87            & 41.72           & 29.13          & 10.89          & 31.99          \\ \hline
		\textit{NGL}        & 46.99          & 27.4             & 51.39           & \textbf{29.83} & 6.05           & 31.25          \\ \hline
		\textit{PIDF}       & 34.85          & 29.41            & 25.45           & 22.65          & 10.12          & 30.5           \\ \hline
		\textit{RF}         & 40.32          & \textbf{34.38}   & \textbf{53.72}  & 26.53          & 10.15          & 30.11          \\ \hline
	\end{tabular}
\end{table}
\subsubsection{Analyse des erreurs}
\subsubsection{Perspectives d'amélioration}

\section{Conclusion}
\label{sec:quanta:conclusion}

