%\chapter{Analyse sémantique de Corpus Textuel par Traitement Automatique du Langage Naturel}
\chapter{Analyse automatique de corpus judiciaires}
\label{chap:literature}

%\cleanchapterquote{A picture is worth a thousand words. An interface is worth a thousand pictures.}{Ben Shneiderman}{(Professor for Computer Science)}

% justice prédictive: limites: fiabilité mathématiques, exhaustivité, résultats différents d'un outils à un autre, quelles données analysées? % necessité: réduire le risque d'erreur d'une 

\section{Introduction}
L'analyse automatique de corpus judiciaires fait partir des nombreuses tâches traitées par les \og{} LegalTech \fg{}. Ces derniers sont en effet des technologies informatiques appliquées à la gamme de domaine lié à la pratique et aux matériaux juridiques \citep{narazenko2017legalnlpintro}.

\section{Analyses pour la prédiction}
%\section{Analyses pour la prédiction}
\label{sec:literature:legalpredict}
%\subsection{Historique}
% https://scholar.google.fr/scholar?cites=7191369298805469698&as_sdt=2005&sciodt=0,5&hl=fr
% https://peerj.com/articles/cs-93/
Le sujet de ce mémoire vise à assister l'analyse quantitative de la prise de décision judiciaire (faisant partie des comportements judiciaires). Il s'agit d'une méthode d'analyse en rupture avec les techniques juridiques traditionnelles déjà critiquées au début des années 60, par des experts de la jurisprudence tels que Karl N. Llewellyn, de souffrir d'une excéssive focalisation sur les règles juridiques qui ne représentent qu'une partie de l'institution juridique \citep{llewellyn1962jurisprudence}. Pour anticiper le comportement judiciaire, plusieurs variables plus ou moins controlables sont indispensables comme le temps, le lieu et les circonstances \citep{ulmer1963quantitative}. Dans notre cas, l'analyse quantitative d'application souhaite profiter du grand nombre de décisions de justice car il est bien connu qu'une collection suffisante d'une certaine forme de données révèle des motifs qui une fois observés sont projetables dans le futur \citep{ulmer1963quantitative}. La prédiction de la prise de décision est ainsi plus accessible que par le formalisme des lois qui ignore l'aléa judiciaire et la spécificité des cas.  Nous discutons dans cette section de quelques techniques d'automatisation de l'analyse quantitative et prédictive des comportements judiciaires, afin de décrire le contexte et justifier les concepts et la granularité judiciaire de notre étude.



%\subsection{Pourquoi une centralité des demandes?}

%\subsection{Floraison d'outils commerciaux}
%\textbf{Mise en relation avec l'avocat approprié:}
%\url{https://actoowin.com/} \url{http://www.legalup.io/} \url{https://www.legalvision.fr/}

%\textbf{calculer automatique des chances de succès d’un litige}: \url{www.predictice.com}



\section{Analyses des données textuelles}
\label{sec:literature:legaltal}

\subsection{Les paradigmes de modélisation}

\subsubsection{Approches discriminantes vs. génératives}

\subsubsection{Approches orientées structure ou pas}

% Survey open tasks: https://arxiv.org/pdf/1707.02919.pdf
% information rechechée ou tâches, contexte geographique - technique, motivation, méthodes
% https://www.law.com/legaltechnews/products-and-software/

Nous discutons, dans les sections suivantes, des travaux explorant l'application de méthodes d'analyse des données textuelles sur des documents judiciaires. La section est structurée suivant les tâches ciblées par ces études.

\subsection{Annotation de document}

L'annotation consiste à enrichir les documents pour préparer ces derniers pour d'autres analyses, faciliter la recherche d'affaires pertinentes, et faire la lumière sur des connaissances linguistiques sous-jacentes au raisonnement juridique. Les éléments annotés peuvent être de très courts segments de texte mentionnant des entités juridiques \citep{Waltl2016lexia, wyner2010extractlegalelts} comme la date, le lieu (juridiction), les noms de juges, des citations de loi.  L'annotation de passages plus longs identifie des concepts juridiques plus complexes comme les faits \citep{wyner2010extractlegalelts, Wyner2010extractcasefactor, Shulayeva2017recognfactprincip}, les définitions \citep{Waltl2016lexia}, des citations de principes juridiques \citep{Shulayeva2017recognfactprincip}, ou des arguments \citep{WynerMoens2010mineargument}. 

Différentes méthodes ont été expérimentées pour l'annotation de documents judiciaires. C'est le cas des modèles probabilistes HMM et CRF que nous étudions dans le chapitre \ref{chap:structuration}. Ils peuvent être combinés à d'autres approches dans un système global. Après avoir segmenter les documents à l'aide d'un modèle CRF, \citet{dozier2010legalnerr} ont combiné plusieurs approches pour reconnaître des entités dans les décisions de la cour suprême des Etats-Unis. Ils ont définis des détecteurs distincts à base de règles pour identifier séparémment la juridiction (zone géographique), le type de document, et les noms des juges, en plus de l'introduction d'une recherche lexicale pour détecter la cour, ainsi qu'un classifieur entrainé pour reconnaître le titre. Ces différents détecteurs ont atteint des performances prometteuses, mais avec des rappels limités entre $ 72 \% $ et $ 87 \% $. Suivant la complexité des éléments à extraire, un système peut comprendre des indexes lexicaux pour les motifs simples et non-systématiques (indicateurs de résultats ou de parties) et les règles pour des motifs plus complexes et systématiques (par ex. noms de juges, énoncés de décisions) \citep{Waltl2016lexia, wyner2010extractlegalelts}. \cite{cardellino2017legalNERCL} quant à eux ont utilisé le CRF et les réseaux de neurones (\textcolor{red}{OÙ pays?}). Les basses performances qu'ils rapportent pour l'extraction dans les jugements illustre bien la difficulté de la détection d'entités juridiques. Plus récemment encore, \citet{andrew2018legalNerAndRelation} obtiennent de bons résultats en combinant l'extraction d'entités non-juridiques par CRF à l'extraction de relations par une grammaire GATE JAPE \citep{thakker2009gatejape} sur des décisions du Luxembourg rédigées en français.

La comparaison avec d'autres approches démontre bien que les modèles probabilistes atteignent de très bonnes performances lors de l'extraction d'information dand les documents juridiques. Par exemple, le HMM a été comparé à l'Algorithme de Perceptron à Marges Inégales (PAUM) \citep{li2002PAUM} pour reconnaître les institutions et références d'autres décisions de justice, ainsi que les citations d'actes juridiques (loi, contrat, etc.) dans les décisions judiciaires de la République Tchèque \citep{Kriz2014nerinczechdecisions}. Les deux modèles ont données de bonnes performances avec des scores F1 de $ 89 \% $ et $ 97 \% $ pour le HMM utilisant les trigrammes comme descripteurs de mots, et des scores F1 de $ 87 \% $ et $ 97 \% $ pour le PAUM en utilisant des 5-grammes de lemmes et les rôles grammaticaux (\textit{Part-Of-Speech tag}) comme descripteurs. 

%\subsubsection{Extraction d'information}
% argument (Grammaire) :\cite{WynerMoens2010mineargument} http://wyner.info/research/Papers/WynerMochalesPalauMoensMilward2009.pdf
% terminologie : https://pdfs.semanticscholar.org/4d49/2d103672723d5683e4fc5b468e49ffaece3b.pdf

\subsection{Classification de texte}
La classification permet d'organiser un corpus en rangeant les textes dans des catégories prédéfinies.  \cite{Aletras2016predictDecisionECHR} identifient s'il y a eu une violation d'un article choisi de la convention des droits de l'homme sur les jugements \footnote{HUDOC ECHR Database: \url{http://hudoc.echr.coe.int}} de la Court Européenne des Droits de l'Hommes (ECHR). Avec un SVM et une représentation vectorielle basée sur les n-grammes les plus fréquents et leur cluster sémantique, ils obtiennent une précision moyenne de 79\% sur les 3 articles qu'ils ont manipulés. Notons tout de même la sélection des régions du documents où sont extraits les N-grammes (circonstances, faits, lois, ...). Cette sélection est un ajustement de la représentation des texte qui paraît nécessaire pour obtenir de bon résultat. La structuration préalable des documents est utile pour réduire le bruit qui occupe généralement plus d'espace que les passages d'intérêt. \cite{sulea2017legalEnsSVM}, d'autre part, traitent de l'identification des résultats dans des arrêts \footnote{Documents de \url{https://www.legifrance.gouv.fr}} de la Court Française de Cassation. Après un essai avec un SVM \citep{Sulea2017predictareadecision}, ils améliorent les résultats à l'aide d'un classifieur ensembliste de SVM à moyenne de probabilités, parvenant ainsi à des F1-mesures de plus de 95\%. 

L'objectif n'est pas toujours l'identification du sens de la décision. \cite{Ashley2009classifCases} entrainent un classifieur (les plus-proches-voisins) pour chacun des 27 facteurs prédéfinis pour savoir s'il s'applique à la décision (phase SMILE). La partie remportant le procès est prédite par un algorithme séquentiel qui compare les parties (plaignant et défendeur) suivant le niveau de préférence des questions juridiques dégagées par les facteurs tel qu'observé dans la base d'entrainement (phase IBP).  D'autres catégorisations, comme la formation judiciaire ou la période du prononcé \citep{Sulea2017predictareadecision,sulea2017legalEnsSVM}, sont toutes aussi utiles pour faciliter la recherche d'information.

\subsection{Similarité et catégorisation non supervisée}
% https://scholar.google.com/scholar?oe=utf-8&client=firefox-b-ab&um=1&ie=UTF-8&lr&cites=2644458803665738328
% https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=6&cad=rja&uact=8&ved=2ahUKEwik05PbjdvdAhUI_qQKHU9UC6QQFjAFegQIAxAC&url=http%3A%2F%2Fweb2py.iiit.ac.in%2Fpublications%2Fdefault%2Fdownload%2Finproceedings.pdf.8d3930f256a00e9c.436f6d707574655f323031315f53757368616e74615f4b756d61722e706466.pdf&usg=AOvVaw3CQX2nPEbeTXt6LhlRoOj6

La similarité entre texte est indispensable pour, entre autres applications, retrouver des textes similaires et catégoriser les documents. La métrique utilisée pour mesurer la similarité entre 2 textes doit être définie ou choisie de telle sorte que qu'on arrive à rapprocher ou éloigner les documents suivant l'aspect sémantique qu'on veut révéler. Les métriques traditionnels peuvent être utilisées sur les décisions judiciaires comme la distance cosinus \citep{thenmozhi2017legalprecedretriev} mais pas toujours avec succès. La raison peut venir notamment de la représentation des textes qui doit accentuer l'aspect sous-jacent de la similarité. \citet{ma2018wmdchinesecase} propose donc de s'appuyer sur une ontologie des concepts et relations du corpus judiciaire. L'idée est de calculer la similarité sur un résumé du texte qui compacte le texte uniquement sur les aspects pertinents. Cette méthode permet ainsi de mieux capter la sémantique pure des jugements, d'avoir une meilleure précision, de réduire la complexité temporelle inhérente à l'exploitation de long document notamment avec la métrique WMD \citep{kusner2015wordmoverdist}.

\section{Conclusion}
\label{sec:literature:conclusion}
\subsection{Types d'approches appliquées}
Un grand nombre de travaux défendent des études de faisabilité. Ils se limitent à appliquer une approche basique d'analyse de données sur une faible quantité de données.


\subsection{Évaluation et qualité}
 Certains articles récents font l'effort de reporter des résultats quantifiés d'évaluation de l'accord inter-annotateurs et du système développé (par ex. \citep{Shulayeva2017recognfactprincip}). Les résultats de la classification des documents sont généralement obtenus à l'issu une validation croisée \cite{Sulea2017predictareadecision,sulea2017legalEnsSVM,Aletras2016predictDecisionECHR}. D'autres ne s'appuient que sur des captures d'écran de l'outil développé pour défendre l'architecture proposée (par ex. \citep{wyner2010extractlegalelts,Waltl2016lexia}).

%\cite{Galgani2015lexa} montrent qu'il est possible en un temps raisonnable d'annoter des texte

