%\chapter{Analyse sémantique de Corpus Textuel par Traitement Automatique du Langage Naturel}
\chapter{Analyse automatique de corpus judiciaires}
\label{chap:literature}


% justice prédictive: limites: fiabilité mathématiques, exhaustivité, résultats différents d'un outils à un autre, quelles données analysées? % necessité: réduire le risque d'erreur d'une 
L'étude bibliographique de ce chapitre est focalisée sur l'application de techniques d'analyse de données textuelles judiciaires avec un accent particulier sur les décisions. L'état de l'art plus technique est décrit dans les chapitres qui traitent, dans la suite, des méthodes que nous avons mises en \oe{}uvre.

\section{Introduction}

% rapport aux théories juridiques: réalisme vs formalisme
Les deux grand paradigmes de jugement se distinguent par l'importance qu'ils accordent aux règles juridiques \citep{tumonis2012legalrealism}. D'une part, les adeptes du Formalisme Juridique, plus partie pertinent dans le droit civil, considèrent que toutes les considérations normatives ont été incorporées dans les lois par leurs auteurs. D'autre part, l'école du Réalisme Juridique, plus proche du droit commun, permet un pouvoir discrétionnaire entre les jugements en raisonnant selon le cas. Les premières tentatives d'anticipation des comportements judiciaires s'appuyaient sur une formalisation des lois. Le \og droit computationnel \fg{} est la sous discipline de  l'\og informatique juridique\footnote{Application les techniques modernes de l'informatique à l'environnement juridique, et par conséquent aux organisations liées au droit} \fg{} qui en est née. Il  s'intéresse, en effet, au raisonnement juridique automatique  axé sur la représentation sémantique riche et plus formelle de la loi, des régulations, et modalités de contrat \citep{love2005computationallaw}. Il vise à réduire la taille et la complexité de la loi pour la rendre plus accessible. Plus précisément, le \og droit computationnel \fg{} propose des systèmes répondant à différentes questions, comme \og Quel montant de taxe dois-je payer cette année? \fg{} (planification juridique), \og Cette régulation contient-elle des règles en contradiction\fg{} \og L'entreprise respecte-t-elle la loi?" (vérification de la conformité) \citep{Genesereth2015computationallaw}. Les techniques pro Formalisme Juridique étaient déjà critiquées au début des années 60, d'être insuffisante car focalisant excessivement sur les règles juridiques qui ne représentent qu'une partie de l'institution juridique \citep{llewellyn1962jurisprudence}. Pour anticiper le comportement judiciaire, plusieurs variables plus ou moins contrôlables, comme le temps, le lieu et les circonstances, doivent aussi être nécessairement prise en compte \citep{ulmer1963quantitative}. Les avocats s'appuyant sur la recherche de précédents, \citet{ulmer1963quantitative} conseille de se concentrer sur les motifs réguliers que comprennent les données pour réaliser des analyses quantitatives. Nous exploitons ainsi la masse de décisions pour identifier de telles régularités car une collection suffisante d'une certaine forme de données révèle des motifs qui une fois observés sont projetables dans le futur \citep{ulmer1963quantitative}. Il s'agit donc de raisonnements à base de cas qui se distinguent du raisonnement à base de règles.

% Généralités sur l'application du text mining / IA en général aux documents juridique: objectifs, données, conférences, commercialisation, activités gouvernementales, inquiétudes ...
Les premiers outils automatiques d'anticipation des décisions étaient généralement des systèmes experts juridiques. Ces derniers résonnent  sur de nouvelles affaires en imitant la prise de décision humaine généralement par la logique et souvent par analogie. Ils s'appuient sur un raisonnement à base de règle c'est-à-dire à partir d'une représentation formelle des connaissances des experts ou du domaine. En droit, il s'agit de la connaissance qu'à l'expert des normes juridiques et de l'ordre des questions à traiter lors du raisonnement sur un cas (appris par expérience). Le modèle explicite de domaine nécessaire ici se trouve dans une base de connaissances où les normes juridiques sont représentées sous forme de \og SI ... ALORS ...\fg{}, et les faits sont généralement représenté dans la logique de prédicat. Un système d’experts juridiques doit s’appuyer sur une base de connaissances juridiques exhaustive et disposer d’un moteur d’inférence capable de trouver les règles pertinentes et le moyen efficace, par déduction, de les appliquer afin d’obtenir la solution du cas actuel aussi rapidement que possible. Des systèmes experts ont échoué dans leur tentative de prédire les décision de justice \citep{leith2010risefall}. La première raison découle de ce que \citet{Berka2011rbr-cbr} a appelé le \og goulot d'acquisition de connaissances \fg{} c'est-à-dire le problème d'obtention des connaissances spécifiques à un domaine d’expertise sous la forme de règles suffisamment générales. L'autre raison tient à l'interprétation ouverte du droit et à la complexité de la formalisation applicable sans tenir compte des particularités de l'affaire.

Contrairement au raisonnement à base de règle, le raisonnement à bas de cas concerne une recherche de solution, une classification ou toute autre inférence pour un cas courant à partir de l'analyse d'anciens cas et de leur solution \citep{moens2002case-basedreasoning}. Un tel système juridique résout les nouveaux cas en rapprochant les cas déjà réglés et en adaptant leurs décisions \citep{Berka2011rbr-cbr}. Le raisonnement fondé sur des cas connaît un succès croissant dans la prédiction de l'issu d'affaire plus aux États-Unis qu'ailleurs. Pour exemple, \citet{katz2014predicting} entraînent des forêts aléatoires sur les cas de 1946-1953 pour prédire si la Cour Suprême infirmera ou confirmera une décision de juridiction inférieure. Ils ont réussi à atteindre 69,7\% des décisions finales pour 7 700 cas des années 1953-2013; des résultats qu'ils ont légèrement améliorés plus récemment en augmentant le nombre d'arbre et la quantité de données \citep{katz2017predictsupremecourt}. D'autre part, \cite{Ashley2009classifCases} ont obtenu une précision de 91,8\% pour prédire la partie qui sera favorisée (plaignant/défendeur) pour les affaires d'appropriation illicite de secrets commerciaux. Contrairement à \citep{katz2014predicting} qui catégorisent les caractéristiques de valeurs prédéfinies pour caractériser la décision débattue, les tribunaux et les juges (opinions politiques, origine de l'affaire, identifiant du juge, raison et sens du dispositif de la cour inférieure), \cite{Ashley2009classifCases} identifient, par classification, des facteurs pouvant influencer la décision. Les valeurs des caractéristiques de ces différents travaux sont prédéfinis et très limités, et ne reflètent pas, par conséquent, la grande diversité de catégories qu'on peut retrouver dans les décisions. 

% introduction des sections suivantes
Nous voulons alimenter les analyses quantitatives de corpus jurisprudentiels en proposant des méthode d'extraction de connaissances dont les références des affaires (juge, date, juridiction, etc.), les règles juridiques associées, les demandes de parties, les réponses des tribunaux, et les liens entre ces données. Les juges apportent une réponse à chaque demande, et par conséquent une partie peut voir ses demandes soit toutes acceptées ou rejetées, soit une partiellement accordées. Un juriste sera donc plus intéressé à formuler les demandes qui ont de meilleures chances d'être acceptées, pour un type de contentieux précis,  qu'à prévoir une victoire du procès. C'est la raison pour laquelle notre analyse se situe à un niveau de granularité plus fin (la demande), contrairement aux travaux sur la prédiction qui traitent d'un résultat global sur la décision (par ex. confirmer/infirmer ou gagner/perdre).  L'identification de ces diverses connaissances est possible par l'analyse sémantique des textes judiciaires grâce aux méthodes du traitement automatique du langage naturel et de l'analyse (ou fouille) de données textuelles. Cependant, l'application de ces techniques exigent certaines adaptations pour surmonter les divers défis posés par les documents juridiques en général \citep{narazenko2017legalnlpintro}: textes très longs et en grande quantité, corpus régulièrement mis à jour, influence subjective de facteurs sociaux et d'opinions politiques, couvertures de problématiques économiques, sociales, politiques très variées, langage complexe, etc. . Dans la suite, nous passons en revue des travaux qui ont été menés dans ce sens pour traiter de problématiques proches des nôtres, en particulier celles décrites précédemment dans l'introduction (Section \ref{subsec:intro:ie}). 

\section{Annotation et extraction d'information}

L'annotation consiste à enrichir les documents pour les préparer à d'autres analyses, faciliter la recherche d'affaires pertinentes, et faire la lumière sur des connaissances linguistiques sous-jacentes au raisonnement juridique. Les éléments annotés peuvent être de très courts segments de texte mentionnant des entités juridiques \citep{Waltl2016lexia, wyner2010extractlegalelts} comme la date, le lieu (juridiction), les noms de juges, des citations de loi.  L'annotation de passages plus longs identifie des concepts juridiques plus complexes comme les faits \citep{wyner2010extractlegalelts, wyner2010casefactors, Shulayeva2017recognfactprincip}, les définitions \citep{Waltl2016lexia}, des citations de principes juridiques \citep{Shulayeva2017recognfactprincip}, ou des arguments \citep{WynerMoens2010mineargument}. 

Différentes méthodes ont été expérimentées pour la reconnaissance d'information dans les documents judiciaires. C'est le cas des modèles probabilistes HMM et CRF que nous étudions dans le chapitre \ref{chap:structuration}. Ils peuvent être combinés à d'autres approches dans un système global. Après avoir segmenter les documents à l'aide d'un modèle CRF, \citet{dozier2010legalnerr} ont combiné plusieurs approches pour reconnaître des entités dans les décisions de la cour suprême des États-Unis. Ils ont définis des détecteurs distincts à base de règles pour identifier séparément la juridiction (zone géographique), le type de document, et les noms des juges, en plus de l'introduction d'une recherche lexicale pour détecter la cour, ainsi qu'un classifieur entraîné pour reconnaître le titre. Ces différents détecteurs ont atteint des performances prometteuses, mais avec des rappels limités entre $ 72 \% $ et $ 87 \% $. Suivant la complexité des éléments à extraire, un système peut comprendre des indexes lexicaux pour les motifs simples et non-systématiques (indicateurs de mentions de résultats ou de parties) et les règles pour des motifs plus complexes et systématiques (par ex. noms de juges, énoncés de décisions) \citep{Waltl2016lexia, wyner2010extractlegalelts}. \cite{cardellino2017legalNERCL} quant à eux ont utilisé le CRF et les réseaux de neurones sur des jugements de la Cour Européenne des Droits de l'Homme. Les basses performances qu'ils rapportent pour l'extraction dans les jugements illustre bien la difficulté de la détection d'entités juridiques. Plus récemment encore, \citet{andrew2018legalNerAndRelation} obtiennent de bons résultats en combinant l'extraction d'entités non-juridiques par CRF à celle des relations entre ces dernières par une grammaire GATE JAPE \citep{thakker2009gatejape} sur des décisions du Luxembourg rédigées en français.

Pour la détection des arguments, par contre, \citet{moens2007NBvsMaxent4arguments} discutent de l'application d'une classification binaire des phrases: \textit{argumentative} / \textit{non-argumentative}. Ils comparent notamment le classifieur bayésien multinomial et le classifieur d'entropie maximum tout en explorant plusieurs caractéristiques textuelles.

% argument (Grammaire) :\cite{WynerMoens2010mineargument} http://wyner.info/research/Papers/WynerMochalesPalauMoensMilward2009.pdf
% terminologie : https://pdfs.semanticscholar.org/4d49/2d103672723d5683e4fc5b468e49ffaece3b.pdf

\section{Classification des documents}
La classification permet d'organiser un corpus en rangeant les documents dans des catégories prédéfinies.  \cite{Aletras2016predictDecisionECHR} identifient s'il y a eu une violation d'un article choisi de la convention des droits de l'homme sur les jugements \footnote{HUDOC ECHR Database: \url{http://hudoc.echr.coe.int}} de la Court Européenne des Droits de l'Hommes (ECHR). Avec un SVM (Machine à Vecteurs de Support) et une représentation vectorielle basée sur les plus fréquents n-grammes et le cluster de leur vecteur de plongement sémantique (word2vec), ils obtiennent une précision moyenne de 79\% sur les 3 articles qu'ils ont manipulés. Notons tout de même la sélection des régions du documents où sont extraits les N-grammes (circonstances, faits, lois, ...). Cette sélection est un ajustement de la représentation des texte qui paraît nécessaire pour obtenir de bon résultat. La structuration préalable des documents est utile pour réduire le bruit qui occupe généralement plus d'espace que les passages d'intérêt.  \citet{medvedeva2018echrCristalBall} étendent ces travaux à neuf articles tout démontrant empiriquement, entre autres, la possibilité de prédire la violation des articles sur des périodes futures à celles des données d'entraînement. \cite{sulea2017legalEnsSVM} traitent, d'autre part, l'identification des résultats dans des arrêts \footnote{Documents de \url{https://www.legifrance.gouv.fr}} de la Court Française de Cassation. Après un essai avec un SVM \citep{Sulea2017predictareadecision}, ils améliorent les résultats à l'aide d'un classifieur ensembliste de SVM à moyenne de probabilités, parvenant ainsi à des F1-mesures de plus de 95\%. 

Par ailleurs, \cite{Ashley2009classifCases} entraînent un classifieur (les plus-proches-voisins) pour chacun des 27 facteurs prédéfinis pour savoir s'il s'applique à la décision (phase SMILE). La partie remportant le procès est prédite par un algorithme séquentiel qui compare les parties (plaignant et défendeur) suivant le niveau de préférence des questions juridiques dégagées par les facteurs tel qu'observé dans la base d'entraînement (phase IBP).  D'autres catégorisations, comme la formation judiciaire ou la période du prononcé \citep{Sulea2017predictareadecision,sulea2017legalEnsSVM}, sont toutes aussi utiles pour faciliter la recherche d'information.

\section{Similarité}
% https://scholar.google.com/scholar?oe=utf-8&client=firefox-b-ab&um=1&ie=UTF-8&lr&cites=2644458803665738328
% https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=6&cad=rja&uact=8&ved=2ahUKEwik05PbjdvdAhUI_qQKHU9UC6QQFjAFegQIAxAC&url=http%3A%2F%2Fweb2py.iiit.ac.in%2Fpublications%2Fdefault%2Fdownload%2Finproceedings.pdf.8d3930f256a00e9c.436f6d707574655f323031315f53757368616e74615f4b756d61722e706466.pdf&usg=AOvVaw3CQX2nPEbeTXt6LhlRoOj6
% quel sémantique fonde la similarité dans chaque travaux? ou comment est défini la similarite entre les documents (dans la sémantique experte) ?
% quelle métrique formalise / numérise / mesure la similarité?
% comment sont évalués les méthodes explorées? contexte d'utilisation et métriques d'évaluation?
% comment sont représentés les documents?

La similarité entre texte est indispensable pour, entre autres applications, retrouver des textes similaires et catégoriser les documents. Parmi les questions liées à l'estimation automatique de la similarité entre documents, on distingue: la sémantique experte qui fonde cette similarité, sa métrique de mesure, la représentation des documents, le contexte d'exploitation et les métriques d'évaluation. La  mesure de similarité doit être définie de sorte à rapprocher ou éloigner les documents suivant l'aspect sémantique qu'on veut révéler. \citet{nair2018judgsimassorule} arrivent à exploiter les citations de lois et précédents car les jugements du droit commun comprennent des liens aux décisions d'affaires similaires antérieures. Ils analyse le réseaux de citations d'un corpus de 597 documents, à l'aide de règle d'association générées par pour . Certaines métriques traditionnels, comme la distance cosinus \citep{thenmozhi2017legalprecedretriev}, ont été utilisées sur les décisions judiciaires mais pas toujours avec succès. La raison peut venir notamment de la représentation des textes qui doit accentuer l'aspect sous-jacent de la similarité. \citet{ma2018wmdchinesecase} proposent donc de s'appuyer sur une ontologie des concepts et relations du corpus judiciaire. L'idée est de calculer la similarité sur un résumé du texte qui compacte le texte uniquement sur les aspects pertinents. Cette méthode permet ainsi de mieux capter la sémantique pure des jugements, d'avoir une meilleure précision, de réduire la complexité temporelle inhérente à l'exploitation de long document notamment avec la métrique WMD \citep{kusner2015wordmoverdist}.

\cite{kumar2011judgmentsimilarity, nair2018judgsimassorule, branting2017autoJudiDocAnalysis}

Les aspects influençant l'estimation de la similarité: l'abstraction à l'information sur laquelle repose la nature de la similarité, la représentation des documents, et la métrique de similarité / dis-similarité employé

\section{Conclusion}
\label{sec:literature:conclusion}
%\subsection{Types d'approches appliquées}
En résumé, l'analyse des données textuelles juridiques a pour but la structuration des documents et l'organisation sémantique de corpus. Le domaine est très actif depuis déjà plusieurs décennies, au point où des librairies de développement, spécifiques au domaine, commencent à voir le jour \citep{bommarito2018lexnlp}.
Un grand nombre de travaux défendent des études de faisabilité. Ils se limitent à appliquer une approche basique d'analyse de données sur une faible quantité de données.

On remarque que le concepteur investit un minimum d'intuitivité ou d'ingénierie que ce soit pour la définition des caractéristiques pour les modèles à apprentissage automatique, ou pour définir les règles pour les méthodes à base de règles ou grammaire. 

%\subsection{Évaluation et qualité}
 Certains articles récents font l'effort de reporter des résultats quantifiés d'évaluation de l'accord inter-annotateurs et du système développé (par ex. \citep{Shulayeva2017recognfactprincip}). Les résultats de la classification des documents sont généralement obtenus à l'issu une validation croisée \cite{Sulea2017predictareadecision,sulea2017legalEnsSVM,Aletras2016predictDecisionECHR}. D'autres ne s'appuient que sur des captures d'écran de l'outil développé pour défendre l'architecture proposée (par ex. \citep{wyner2010extractlegalelts,Waltl2016lexia}).

%\cite{Galgani2015lexa} montrent qu'il est possible en un temps raisonnable d'annoter des texte

